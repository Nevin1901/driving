{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.io import VideoReader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import cv2 as cv\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return idx-1\n",
    "    \n",
    "    else:\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got videos\n"
     ]
    }
   ],
   "source": [
    "def get_videos_for_chunk(num):\n",
    "    # Pre process data\n",
    "\n",
    "    base_dir = f\"/media/nevin/Trash Games1/Downloads/comma2k19/extracted/Chunk_{num}\"\n",
    "    save_dir = \"/media/nevin/Trash Games1/Downloads/comma2k19/processed\"\n",
    "\n",
    "    dirs = os.listdir(base_dir)\n",
    "\n",
    "    videos = []\n",
    "\n",
    "    for _dir in dirs:\n",
    "        project_dir = os.path.join(base_dir, _dir)\n",
    "        segments = os.listdir(project_dir)\n",
    "\n",
    "\n",
    "        for segment in segments:\n",
    "            seg_dir = os.path.join(project_dir, segment)\n",
    "            video_path = os.path.join(seg_dir, \"video.hevc\")\n",
    "\n",
    "            frame_times = os.path.join(seg_dir, \"global_pose/\", \"frame_times\")\n",
    "            angle_t = os.path.join(seg_dir, \"processed_log/\", \"CAN/\", \"steering_angle/\", \"t\")\n",
    "            angle_v = os.path.join(seg_dir, \"processed_log/\", \"CAN/\", \"steering_angle/\", \"value\")\n",
    "    # self, vid_path, ft_path, angle_t_path, angle_v_path\n",
    "            videos.append(VideoWithInfo(video_path, frame_times, angle_t, angle_v))\n",
    "    \n",
    "    return VideoAngleDataset(videos[:20])\n",
    "\n",
    "train_dataset = get_videos_for_chunk(1)\n",
    "test_dataset = get_videos_for_chunk(2)\n",
    "\n",
    "print(\"got videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoAngleDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, videos):\n",
    "        super(VideoAngleDataset).__init__()\n",
    "        self.videos = videos\n",
    "        self.video = None\n",
    "    \n",
    "\n",
    "    def __iter__(self):\n",
    "        self.vid_idx = 0\n",
    "        self.current_vid = None\n",
    "        self.frame_idx = 0\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def __next__(self):\n",
    "        if self.vid_idx >= len(self.videos):\n",
    "            raise StopIteration\n",
    "\n",
    "        if self.current_vid == None:\n",
    "            self.current_vid = iter(self.videos[self.vid_idx])\n",
    "        \n",
    "        frame = next(self.current_vid, None)\n",
    "        if frame == None:\n",
    "            self.vid_idx += 1\n",
    "\n",
    "            if self.vid_idx >= len(self.videos):\n",
    "                raise StopIteration\n",
    "\n",
    "            self.current_vid = iter(self.videos[self.vid_idx])\n",
    "            frame = next(self.current_vid)\n",
    "\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoWithInfo:\n",
    "    def __init__(self, vid_path, ft_path, angle_t_path, angle_v_path):\n",
    "        self.vid_path = vid_path\n",
    "        self.ft_path = ft_path\n",
    "        self.angle_t_path = angle_t_path\n",
    "        self.angle_v_path = angle_v_path\n",
    "        self.video = None\n",
    "    \n",
    "\n",
    "    def __iter__(self):\n",
    "        self.video = cv.VideoCapture(self.vid_path)\n",
    "        self.frame_times = np.load(self.ft_path)\n",
    "        self.angle_t = np.load(self.angle_t_path)\n",
    "        self.angle_v = np.load(self.angle_v_path)\n",
    "        self.frame_idx = 0\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.video.isOpened() == False:\n",
    "            raise StopIteration\n",
    "        \n",
    "        status, frame = self.video.read()\n",
    "\n",
    "        if status == False:\n",
    "            raise StopIteration\n",
    "        \n",
    "\n",
    "        resized = cv.resize(frame, (129, 97))\n",
    "        resized = cv.cvtColor(resized, cv.COLOR_BGR2RGB)\n",
    "        tensor = transform(resized)\n",
    "\n",
    "        rot_idx = find_nearest(self.angle_t, self.frame_times[self.frame_idx])\n",
    "        angle = self.angle_v[rot_idx]\n",
    "\n",
    "        self.frame_idx += 1\n",
    "\n",
    "        return {'tensor': tensor, 'frame': frame, 'angle': angle}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/media/nevin/Trash Games1/Downloads/comma2k19/extracted/Chunk_1/b0c9d2329ad1606b_2018-07-27--06-03-57\"\n",
    "wheel = cv.imread(\"/home/nevin/Downloads/wheel.png\")\n",
    "video_1 = VideoWithInfo(f\"{base_dir}/3/video.hevc\", f\"{base_dir}/3/global_pose/frame_times\", f\"{base_dir}/3/processed_log/CAN/steering_angle/t\", f\"{base_dir}/3/processed_log/CAN/steering_angle/value\")\n",
    "video_2 = VideoWithInfo(f\"{base_dir}/4/video.hevc\", f\"{base_dir}/4/global_pose/frame_times\", f\"{base_dir}/4/processed_log/CAN/steering_angle/t\", f\"{base_dir}/4/processed_log/CAN/steering_angle/value\")\n",
    "\n",
    "videos = [video_1, video_2]\n",
    "dataset = VideoAngleDataset(videos)\n",
    "\n",
    "for frame in dataset:\n",
    "    # print(frame[\"frame\"].shape)\n",
    "    rotated = rotate_image(wheel, frame[\"angle\"])\n",
    "    # print(frame[\"tensor\"].shape)\n",
    "    # normal numpy().transpose(1, 2, 0)\n",
    "    cv.imshow(\"frame\", frame[\"frame\"])\n",
    "    cv.imshow(\"wheel\", rotated)\n",
    "\n",
    "    key = cv.waitKey()\n",
    "\n",
    "    if key == 113:\n",
    "        cv.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "# print(sys.getsizeof(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"got here 1\")\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class AutoDrive(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoDrive, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # PrintLayer(),\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(in_channels=8, out_channels=12, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=20, kernel_size=3, stride=1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(in_channels=20, out_channels=22, kernel_size=3, stride=1)\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(990, 480),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(480, 120),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(120, 70),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(70, 10),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_layers(x)\n",
    "        # print(\"got here\")\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.024996, batch: 0\n",
      "loss: 3.504597, batch: 100\n",
      "loss: 0.067881, batch: 200\n",
      "loss: 1.006213, batch: 300\n",
      "loss: 1.326488, batch: 400\n",
      "loss: 0.127966, batch: 500\n",
      "loss: 17.440996, batch: 600\n",
      "loss: 0.005894, batch: 700\n",
      "loss: 0.005116, batch: 800\n",
      "loss: 0.034407, batch: 900\n",
      "loss: 3.480537, batch: 1000\n",
      "loss: 0.250694, batch: 1100\n",
      "loss: 0.024224, batch: 1200\n",
      "loss: 2.377019, batch: 1300\n",
      "loss: 0.802102, batch: 1400\n",
      "loss: 53.818317, batch: 1500\n",
      "loss: 2.493272, batch: 1600\n",
      "loss: 0.226461, batch: 1700\n",
      "loss: 1.273128, batch: 1800\n",
      "loss: 31.803204, batch: 1900\n",
      "loss: 194.403580, batch: 2000\n",
      "loss: 281.361969, batch: 2100\n",
      "loss: 192.810181, batch: 2200\n",
      "loss: 109.303734, batch: 2300\n",
      "loss: 55.643318, batch: 2400\n",
      "loss: 10.421726, batch: 2500\n",
      "loss: 23.023067, batch: 2600\n",
      "loss: 549.032654, batch: 2700\n",
      "loss: 7.002925, batch: 2800\n",
      "loss: 0.820114, batch: 2900\n",
      "loss: 4.078269, batch: 3000\n",
      "loss: 1.904649, batch: 3100\n",
      "loss: 3.652811, batch: 3200\n",
      "loss: 5.814215, batch: 3300\n",
      "loss: 0.033741, batch: 3400\n",
      "loss: 0.012560, batch: 3500\n",
      "loss: 13.272155, batch: 3600\n",
      "loss: 0.235628, batch: 3700\n",
      "loss: 0.514848, batch: 3800\n",
      "loss: 16.770184, batch: 3900\n",
      "loss: 2.616773, batch: 4000\n",
      "loss: 0.585832, batch: 4100\n",
      "loss: 1.430819, batch: 4200\n",
      "loss: 0.156632, batch: 4300\n",
      "loss: 2.501083, batch: 4400\n",
      "loss: 1.543699, batch: 4500\n",
      "loss: 0.910046, batch: 4600\n",
      "loss: 0.399815, batch: 4700\n",
      "loss: 0.209167, batch: 4800\n",
      "loss: 0.106622, batch: 4900\n",
      "loss: 246.245163, batch: 5000\n",
      "loss: 34.355602, batch: 5100\n",
      "loss: 90.860947, batch: 5200\n",
      "loss: 1.905811, batch: 5300\n",
      "loss: 5.163540, batch: 5400\n",
      "loss: 31.775667, batch: 5500\n",
      "loss: 14.125936, batch: 5600\n",
      "loss: 5.406577, batch: 5700\n",
      "loss: 8.200289, batch: 5800\n",
      "loss: 2.654067, batch: 5900\n",
      "loss: 5.229121, batch: 6000\n",
      "loss: 7.127675, batch: 6100\n",
      "loss: 0.025117, batch: 6200\n",
      "loss: 11.193917, batch: 6300\n",
      "loss: 11.282728, batch: 6400\n",
      "loss: 0.020938, batch: 6500\n",
      "loss: 0.772970, batch: 6600\n",
      "loss: 1.345593, batch: 6700\n",
      "loss: 41.448036, batch: 6800\n",
      "loss: 8.744576, batch: 6900\n",
      "loss: 74.582367, batch: 7000\n",
      "loss: 13.172844, batch: 7100\n",
      "loss: 0.197060, batch: 7200\n",
      "loss: 0.023384, batch: 7300\n",
      "loss: 1.023641, batch: 7400\n",
      "loss: 30.861185, batch: 7500\n",
      "loss: 35.912460, batch: 7600\n",
      "loss: 9.146956, batch: 7700\n",
      "loss: 7.779134, batch: 7800\n",
      "loss: 0.180986, batch: 7900\n",
      "loss: 0.183282, batch: 8000\n",
      "loss: 0.981591, batch: 8100\n",
      "loss: 7.140493, batch: 8200\n",
      "loss: 5.162248, batch: 8300\n",
      "loss: 6.145111, batch: 8400\n",
      "loss: 33.839390, batch: 8500\n",
      "loss: 6.101246, batch: 8600\n",
      "loss: 11.332191, batch: 8700\n",
      "loss: 6.937221, batch: 8800\n",
      "loss: 22.691252, batch: 8900\n",
      "loss: 22.071718, batch: 9000\n",
      "loss: 7.013350, batch: 9100\n",
      "loss: 3.427846, batch: 9200\n",
      "loss: 3.660040, batch: 9300\n",
      "loss: 2.150097, batch: 9400\n",
      "loss: 57.979797, batch: 9500\n",
      "loss: 51.970905, batch: 9600\n",
      "loss: 18.832567, batch: 9700\n",
      "loss: 5.358796, batch: 9800\n",
      "loss: 3.420751, batch: 9900\n",
      "loss: 14.169658, batch: 10000\n",
      "loss: 2.123432, batch: 10100\n",
      "loss: 3.211241, batch: 10200\n",
      "loss: 0.202658, batch: 10300\n",
      "loss: 10.136338, batch: 10400\n",
      "loss: 0.420030, batch: 10500\n",
      "loss: 50.989964, batch: 10600\n",
      "loss: 1.877750, batch: 10700\n",
      "loss: 25.971807, batch: 10800\n",
      "loss: 12.481727, batch: 10900\n",
      "loss: 8.863720, batch: 11000\n",
      "loss: 38.443550, batch: 11100\n",
      "loss: 12.980691, batch: 11200\n",
      "loss: 13.791161, batch: 11300\n",
      "loss: 21.089674, batch: 11400\n",
      "loss: 9.833427, batch: 11500\n",
      "loss: 6.403863, batch: 11600\n",
      "loss: 8.639376, batch: 11700\n",
      "loss: 5.095205, batch: 11800\n",
      "loss: 2.102224, batch: 11900\n",
      "loss: 2.081657, batch: 12000\n",
      "loss: 0.335038, batch: 12100\n",
      "loss: 49.190865, batch: 12200\n",
      "loss: 49.027897, batch: 12300\n",
      "loss: 10.404774, batch: 12400\n",
      "loss: 2.692609, batch: 12500\n",
      "loss: 0.002451, batch: 12600\n",
      "loss: 12.988571, batch: 12700\n",
      "loss: 0.005600, batch: 12800\n",
      "loss: 3.353818, batch: 12900\n",
      "loss: 2.444426, batch: 13000\n",
      "loss: 40.729271, batch: 13100\n",
      "loss: 0.031093, batch: 13200\n",
      "loss: 0.095568, batch: 13300\n",
      "loss: 0.019014, batch: 13400\n",
      "loss: 26.620323, batch: 13500\n",
      "loss: 0.903107, batch: 13600\n",
      "loss: 44.037403, batch: 13700\n",
      "loss: 3.912639, batch: 13800\n",
      "loss: 3.729024, batch: 13900\n",
      "loss: 0.452921, batch: 14000\n",
      "loss: 16.139692, batch: 14100\n",
      "loss: 0.001719, batch: 14200\n",
      "loss: 0.878900, batch: 14300\n",
      "loss: 4.862402, batch: 14400\n",
      "loss: 1.264559, batch: 14500\n",
      "loss: 6.616494, batch: 14600\n",
      "loss: 0.010093, batch: 14700\n",
      "loss: 10.020224, batch: 14800\n",
      "loss: 0.324297, batch: 14900\n",
      "loss: 1.852540, batch: 15000\n",
      "loss: 1.007059, batch: 15100\n",
      "loss: 0.062989, batch: 15200\n",
      "loss: 17.254498, batch: 15300\n",
      "loss: 233.528168, batch: 15400\n",
      "loss: 2.980368, batch: 15500\n",
      "loss: 2.810505, batch: 15600\n",
      "loss: 4.185492, batch: 15700\n",
      "loss: 1.458536, batch: 15800\n",
      "loss: 0.058522, batch: 15900\n",
      "loss: 4.090830, batch: 16000\n",
      "loss: 0.060223, batch: 16100\n",
      "loss: 0.215069, batch: 16200\n",
      "loss: 18.298496, batch: 16300\n",
      "loss: 0.061915, batch: 16400\n",
      "loss: 0.009524, batch: 16500\n",
      "loss: 0.352631, batch: 16600\n",
      "loss: 3.682772, batch: 16700\n",
      "loss: 15.097544, batch: 16800\n",
      "loss: 0.596362, batch: 16900\n",
      "loss: 172.207077, batch: 17000\n",
      "loss: 32.684689, batch: 17100\n",
      "loss: 23.033360, batch: 17200\n",
      "loss: 8.326918, batch: 17300\n",
      "loss: 424.442139, batch: 17400\n",
      "loss: 4.476245, batch: 17500\n",
      "loss: 27.071627, batch: 17600\n",
      "loss: 11.604066, batch: 17700\n",
      "loss: 8.013393, batch: 17800\n",
      "loss: 0.180490, batch: 17900\n",
      "loss: 21.819706, batch: 18000\n",
      "loss: 12.071845, batch: 18100\n",
      "loss: 43.648094, batch: 18200\n",
      "loss: 1.209127, batch: 18300\n",
      "loss: 4.037172, batch: 18400\n",
      "loss: 8.834286, batch: 18500\n",
      "loss: 16.981920, batch: 18600\n",
      "loss: 15.226815, batch: 18700\n",
      "loss: 1.799760, batch: 18800\n",
      "loss: 70.958885, batch: 18900\n",
      "loss: 77.291580, batch: 19000\n",
      "loss: 7.537360, batch: 19100\n",
      "loss: 3.457305, batch: 19200\n",
      "loss: 2.322281, batch: 19300\n",
      "loss: 14.125072, batch: 19400\n",
      "loss: 41.255009, batch: 19500\n",
      "loss: 4.943306, batch: 19600\n",
      "loss: 0.113671, batch: 19700\n",
      "loss: 1.012961, batch: 19800\n",
      "loss: 0.194698, batch: 19900\n",
      "loss: 1.105912, batch: 20000\n",
      "loss: 0.245035, batch: 20100\n",
      "loss: 0.001651, batch: 20200\n",
      "loss: 0.419124, batch: 20300\n",
      "loss: 0.291864, batch: 20400\n",
      "loss: 0.334194, batch: 20500\n",
      "loss: 0.297515, batch: 20600\n",
      "loss: 35.843540, batch: 20700\n",
      "loss: 8.824396, batch: 20800\n",
      "loss: 3.769503, batch: 20900\n",
      "loss: 0.834568, batch: 21000\n",
      "loss: 11.804541, batch: 21100\n",
      "loss: 0.833157, batch: 21200\n",
      "loss: 2.296301, batch: 21300\n",
      "loss: 0.031973, batch: 21400\n",
      "loss: 0.766416, batch: 21500\n",
      "loss: 1471.290405, batch: 21600\n",
      "loss: 129.116440, batch: 21700\n",
      "loss: 22.540113, batch: 21800\n",
      "loss: 12.179974, batch: 21900\n",
      "loss: 23.594505, batch: 22000\n",
      "loss: 37.981354, batch: 22100\n",
      "loss: 1.111443, batch: 22200\n",
      "loss: 10.529764, batch: 22300\n",
      "loss: 1786.537842, batch: 22400\n",
      "loss: 20313.666016, batch: 22500\n",
      "loss: 3.608088, batch: 22600\n",
      "loss: 0.251726, batch: 22700\n",
      "loss: 2.155979, batch: 22800\n",
      "loss: 38.929432, batch: 22900\n",
      "loss: 50.501972, batch: 23000\n",
      "loss: 15.020520, batch: 23100\n",
      "loss: 0.097828, batch: 23200\n",
      "loss: 20.812925, batch: 23300\n",
      "loss: 0.645795, batch: 23400\n",
      "loss: 0.342169, batch: 23500\n",
      "loss: 6.985568, batch: 23600\n",
      "loss: 1.958929, batch: 23700\n",
      "loss: 0.424171, batch: 23800\n",
      "loss: 1.670632, batch: 23900\n",
      "Epoch 1\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optim):\n",
    "    for batch, frame in enumerate(dataloader):\n",
    "        tensor = frame[\"tensor\"].to(\"cuda\")\n",
    "        angle = frame[\"angle\"].float().to(\"cuda\")\n",
    "        pred = model(tensor)\n",
    "\n",
    "        loss = loss_fn(pred[0], angle)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"loss: {loss:>7f}, batch: {current}\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    test_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for frame in dataloader:\n",
    "            tensor = frame[\"tensor\"].to(\"cuda\")\n",
    "            angle = frame[\"angle\"].float().to(\"cuda\")\n",
    "\n",
    "            pred = model(tensor)\n",
    "            test_loss += loss_fn(pred[0], angle).item()\n",
    "            test_loss /= 2\n",
    "    \n",
    "    print(f\"test error: {test_loss:>8f}\")\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "model = AutoDrive().to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "    print(f\"Epoch {i+1}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"/media/nevin/Trash Games1/Downloads/comma2k19/processed/model.pth\")\n",
    "print(\"saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n",
      "0.8741414\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for frame in test_dataset:\n",
    "\n",
    "        pred = model(frame[\"tensor\"].to(\"cuda\")[None, ...])\n",
    "        print(np.asarray(pred[0].to(\"cpu\"))[0])\n",
    "        rotated = rotate_image(wheel, np.asarray(pred[0].to(\"cpu\"))[0])\n",
    "        cv.imshow(\"frame\", frame[\"frame\"])\n",
    "        cv.imshow(\"angle\", rotated)\n",
    "        # pred = model(frame[\"tensor\"].to(\"cuda\"))\n",
    "        # print(pred)\n",
    "\n",
    "        key = cv.waitKey()\n",
    "\n",
    "        if key == 113:\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44a7e8bb18bc21ad5a0a653f082c7df91354cfeb6d74e97b2b6f41bba6c7f85f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('3.8.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
